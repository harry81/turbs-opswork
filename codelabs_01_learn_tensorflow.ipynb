{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codelabs_01_learn_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harry81/turbs-opswork/blob/master/codelabs_01_learn_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzHJZxDijypX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B_IaRUTkFY2",
        "colab_type": "code",
        "outputId": "5db9d01b-64bc-409f-e8c7-220ff40ce330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [keras.layers.Dense(units=1, input_shape=[1])]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 08:32:44.219926 140243023656832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSlGfr6kkSue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpM9vfceklBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "xy = np.array([-2.0, 1.0, 4.0, 7.0, 10.0, 13.0], dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiTQN0jJkxka",
        "colab_type": "code",
        "outputId": "e2a0b73f-5adc-46a6-fb8d-9d1ca32b678a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        }
      },
      "source": [
        "model.fit(xs, xy, epochs=500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 1s 84ms/sample - loss: 23.0979\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 414us/sample - loss: 18.1882\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 518us/sample - loss: 14.3252\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 362us/sample - loss: 11.2856\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 284us/sample - loss: 8.8939\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 285us/sample - loss: 7.0119\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 5.5310\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 171us/sample - loss: 4.3655\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 169us/sample - loss: 3.4483\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 2.7265\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 2.1582\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 1.7109\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 166us/sample - loss: 1.3587\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 1.0814\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 165us/sample - loss: 0.8629\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 165us/sample - loss: 0.6908\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 168us/sample - loss: 0.5551\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 165us/sample - loss: 0.4481\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 0.3637\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 189us/sample - loss: 0.2971\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 163us/sample - loss: 0.2445\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 155us/sample - loss: 0.2028\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 159us/sample - loss: 0.1699\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 0.1437\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 168us/sample - loss: 0.1229\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 158us/sample - loss: 0.1064\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 182us/sample - loss: 0.0932\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0826\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0740\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 180us/sample - loss: 0.0671\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 159us/sample - loss: 0.0615\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0569\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 210us/sample - loss: 0.0531\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 205us/sample - loss: 0.0500\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 174us/sample - loss: 0.0473\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 163us/sample - loss: 0.0451\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 0.0432\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 176us/sample - loss: 0.0415\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 0.0400\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 195us/sample - loss: 0.0387\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 0.0375\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 195us/sample - loss: 0.0365\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 217us/sample - loss: 0.0355\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 0.0346\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0337\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 164us/sample - loss: 0.0329\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 0.0321\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 211us/sample - loss: 0.0314\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0307\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 0.0300\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 0.0294\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 0.0287\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 161us/sample - loss: 0.0281\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 202us/sample - loss: 0.0275\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 166us/sample - loss: 0.0269\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 247us/sample - loss: 0.0264\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 208us/sample - loss: 0.0258\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 172us/sample - loss: 0.0253\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 308us/sample - loss: 0.0248\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 170us/sample - loss: 0.0243\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 215us/sample - loss: 0.0238\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 182us/sample - loss: 0.0233\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 198us/sample - loss: 0.0228\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 163us/sample - loss: 0.0223\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 207us/sample - loss: 0.0219\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 239us/sample - loss: 0.0214\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 0.0210\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 225us/sample - loss: 0.0205\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 160us/sample - loss: 0.0201\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 0.0197\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0193\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 194us/sample - loss: 0.0189\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0185\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 212us/sample - loss: 0.0181\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 223us/sample - loss: 0.0178\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 183us/sample - loss: 0.0174\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 195us/sample - loss: 0.0170\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 168us/sample - loss: 0.0167\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 164us/sample - loss: 0.0163\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 0.0160\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 345us/sample - loss: 0.0157\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 0.0154\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 0.0150\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 163us/sample - loss: 0.0147\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0144\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 0.0141\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 328us/sample - loss: 0.0138\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 174us/sample - loss: 0.0136\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 0.0133\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0130\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 278us/sample - loss: 0.0127\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 0.0125\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 194us/sample - loss: 0.0122\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 185us/sample - loss: 0.0120\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 161us/sample - loss: 0.0117\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 0.0115\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0112\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 0.0110\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 0.0108\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 0.0106\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0104\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 186us/sample - loss: 0.0101\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 198us/sample - loss: 0.0099\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 0.0097\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 203us/sample - loss: 0.0095\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 160us/sample - loss: 0.0093\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 186us/sample - loss: 0.0091\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 0.0090\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0088\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 0.0086\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 184us/sample - loss: 0.0084\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 0.0082\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 0.0081\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 194us/sample - loss: 0.0079\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 177us/sample - loss: 0.0077\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0076\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 178us/sample - loss: 0.0074\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0073\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0071\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0070\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0068\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 0.0067\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 0.0066\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0064\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 353us/sample - loss: 0.0063\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 296us/sample - loss: 0.0062\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0060\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 0.0059\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 291us/sample - loss: 0.0058\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0057\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 186us/sample - loss: 0.0056\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 0.0054\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 0.0053\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0052\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 0.0051\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 266us/sample - loss: 0.0050\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0049\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 0.0048\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0047\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 182us/sample - loss: 0.0046\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 0.0045\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0044\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 184us/sample - loss: 0.0043\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 179us/sample - loss: 0.0042\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 0.0042\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 0.0041\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 0.0040\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0039\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 205us/sample - loss: 0.0038\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 200us/sample - loss: 0.0037\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 160us/sample - loss: 0.0037\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 161us/sample - loss: 0.0036\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 177us/sample - loss: 0.0035\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 0.0034\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 180us/sample - loss: 0.0034\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 168us/sample - loss: 0.0033\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 0.0032\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 182us/sample - loss: 0.0032\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 0.0031\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 287us/sample - loss: 0.0030\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 0.0030\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 164us/sample - loss: 0.0029\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 163us/sample - loss: 0.0029\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 206us/sample - loss: 0.0028\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 216us/sample - loss: 0.0027\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 0.0027\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0026\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 303us/sample - loss: 0.0026\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 211us/sample - loss: 0.0025\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 202us/sample - loss: 0.0025\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 235us/sample - loss: 0.0024\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 257us/sample - loss: 0.0024\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 0.0023\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 213us/sample - loss: 0.0023\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 0.0022\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 0.0022\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 0.0021\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 0.0021\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 0.0021\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 206us/sample - loss: 0.0020\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 0.0020\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 205us/sample - loss: 0.0019\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 0.0019\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 229us/sample - loss: 0.0018\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 212us/sample - loss: 0.0018\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 255us/sample - loss: 0.0018\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 166us/sample - loss: 0.0017\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 200us/sample - loss: 0.0017\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 206us/sample - loss: 0.0017\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 205us/sample - loss: 0.0016\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 200us/sample - loss: 0.0016\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 0.0016\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 276us/sample - loss: 0.0015\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 265us/sample - loss: 0.0015\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0015\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 203us/sample - loss: 0.0014\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 202us/sample - loss: 0.0014\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 173us/sample - loss: 0.0014\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 327us/sample - loss: 0.0014\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 317us/sample - loss: 0.0013\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 301us/sample - loss: 0.0013\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 366us/sample - loss: 0.0013\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 168us/sample - loss: 0.0012\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 412us/sample - loss: 0.0012\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 200us/sample - loss: 0.0012\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 297us/sample - loss: 0.0012\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 0.0011\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 212us/sample - loss: 0.0011\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 0.0011\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 203us/sample - loss: 0.0011\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 0.0011\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 228us/sample - loss: 0.0010\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 166us/sample - loss: 0.0010\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 9.9201e-04\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 203us/sample - loss: 9.7164e-04\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 198us/sample - loss: 9.5168e-04\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 9.3212e-04\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 203us/sample - loss: 9.1298e-04\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 203us/sample - loss: 8.9422e-04\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 244us/sample - loss: 8.7586e-04\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 291us/sample - loss: 8.5787e-04\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 267us/sample - loss: 8.4025e-04\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 202us/sample - loss: 8.2299e-04\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 207us/sample - loss: 8.0609e-04\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 218us/sample - loss: 7.8953e-04\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 268us/sample - loss: 7.7331e-04\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 175us/sample - loss: 7.5743e-04\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 174us/sample - loss: 7.4187e-04\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 7.2663e-04\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 288us/sample - loss: 7.1170e-04\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 320us/sample - loss: 6.9708e-04\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 316us/sample - loss: 6.8276e-04\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 275us/sample - loss: 6.6874e-04\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 182us/sample - loss: 6.5501e-04\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 175us/sample - loss: 6.4155e-04\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 314us/sample - loss: 6.2837e-04\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 6.1546e-04\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 212us/sample - loss: 6.0282e-04\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 213us/sample - loss: 5.9044e-04\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 5.7831e-04\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 169us/sample - loss: 5.6643e-04\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 251us/sample - loss: 5.5480e-04\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 315us/sample - loss: 5.4340e-04\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 179us/sample - loss: 5.3224e-04\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 5.2131e-04\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 208us/sample - loss: 5.1060e-04\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 242us/sample - loss: 5.0012e-04\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 4.8984e-04\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 205us/sample - loss: 4.7978e-04\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 281us/sample - loss: 4.6992e-04\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 238us/sample - loss: 4.6027e-04\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 296us/sample - loss: 4.5082e-04\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 4.4156e-04\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 4.3249e-04\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 257us/sample - loss: 4.2361e-04\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 198us/sample - loss: 4.1490e-04\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 4.0638e-04\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 3.9803e-04\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 3.8986e-04\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 198us/sample - loss: 3.8185e-04\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 211us/sample - loss: 3.7401e-04\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 295us/sample - loss: 3.6633e-04\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 3.5880e-04\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 3.5143e-04\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 206us/sample - loss: 3.4421e-04\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 3.3715e-04\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 280us/sample - loss: 3.3022e-04\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 206us/sample - loss: 3.2344e-04\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 226us/sample - loss: 3.1679e-04\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 217us/sample - loss: 3.1029e-04\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 3.0392e-04\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 2.9767e-04\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 169us/sample - loss: 2.9156e-04\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 177us/sample - loss: 2.8556e-04\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 271us/sample - loss: 2.7970e-04\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 237us/sample - loss: 2.7396e-04\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 313us/sample - loss: 2.6833e-04\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 298us/sample - loss: 2.6282e-04\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 306us/sample - loss: 2.5742e-04\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 2.5213e-04\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 283us/sample - loss: 2.4695e-04\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 2.4188e-04\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 313us/sample - loss: 2.3691e-04\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 249us/sample - loss: 2.3204e-04\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 214us/sample - loss: 2.2728e-04\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 212us/sample - loss: 2.2261e-04\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 234us/sample - loss: 2.1804e-04\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 206us/sample - loss: 2.1356e-04\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 356us/sample - loss: 2.0917e-04\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 220us/sample - loss: 2.0488e-04\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 198us/sample - loss: 2.0067e-04\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 1.9655e-04\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 1.9251e-04\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 1.8856e-04\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 282us/sample - loss: 1.8468e-04\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 217us/sample - loss: 1.8089e-04\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 210us/sample - loss: 1.7717e-04\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 176us/sample - loss: 1.7354e-04\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 165us/sample - loss: 1.6997e-04\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 294us/sample - loss: 1.6648e-04\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 1.6306e-04\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 1.5971e-04\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 209us/sample - loss: 1.5643e-04\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 168us/sample - loss: 1.5322e-04\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 430us/sample - loss: 1.5007e-04\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 160us/sample - loss: 1.4699e-04\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 1.4397e-04\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 285us/sample - loss: 1.4101e-04\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 266us/sample - loss: 1.3811e-04\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 299us/sample - loss: 1.3528e-04\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 206us/sample - loss: 1.3250e-04\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 1.2978e-04\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 1.2711e-04\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 313us/sample - loss: 1.2450e-04\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 189us/sample - loss: 1.2194e-04\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 1.1944e-04\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 290us/sample - loss: 1.1698e-04\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 294us/sample - loss: 1.1458e-04\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 186us/sample - loss: 1.1223e-04\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 1.0992e-04\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 1.0767e-04\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 1.0546e-04\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 1.0329e-04\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 268us/sample - loss: 1.0117e-04\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 281us/sample - loss: 9.9089e-05\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 164us/sample - loss: 9.7054e-05\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 163us/sample - loss: 9.5060e-05\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 311us/sample - loss: 9.3106e-05\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 9.1195e-05\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 8.9320e-05\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 8.7486e-05\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 275us/sample - loss: 8.5690e-05\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 294us/sample - loss: 8.3930e-05\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 262us/sample - loss: 8.2204e-05\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 8.0516e-05\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 287us/sample - loss: 7.8861e-05\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 7.7242e-05\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 209us/sample - loss: 7.5655e-05\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 7.4101e-05\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 270us/sample - loss: 7.2579e-05\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 315us/sample - loss: 7.1087e-05\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 209us/sample - loss: 6.9628e-05\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 207us/sample - loss: 6.8197e-05\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 183us/sample - loss: 6.6796e-05\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 262us/sample - loss: 6.5425e-05\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 6.4081e-05\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 6.2763e-05\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 259us/sample - loss: 6.1474e-05\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 166us/sample - loss: 6.0211e-05\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 209us/sample - loss: 5.8975e-05\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 5.7764e-05\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 287us/sample - loss: 5.6576e-05\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 5.5414e-05\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 280us/sample - loss: 5.4276e-05\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 300us/sample - loss: 5.3160e-05\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 5.2069e-05\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 5.0999e-05\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 184us/sample - loss: 4.9951e-05\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 4.8926e-05\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 195us/sample - loss: 4.7921e-05\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 4.6937e-05\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 272us/sample - loss: 4.5973e-05\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 262us/sample - loss: 4.5029e-05\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 204us/sample - loss: 4.4104e-05\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 4.3198e-05\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 4.2310e-05\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 222us/sample - loss: 4.1441e-05\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 186us/sample - loss: 4.0591e-05\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 169us/sample - loss: 3.9756e-05\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 169us/sample - loss: 3.8939e-05\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 3.8139e-05\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 162us/sample - loss: 3.7355e-05\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 180us/sample - loss: 3.6589e-05\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 172us/sample - loss: 3.5838e-05\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 163us/sample - loss: 3.5102e-05\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 253us/sample - loss: 3.4381e-05\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 3.3674e-05\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 282us/sample - loss: 3.2983e-05\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 3.2305e-05\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 3.1642e-05\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 231us/sample - loss: 3.0992e-05\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 3.0356e-05\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 2.9733e-05\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 2.9121e-05\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 200us/sample - loss: 2.8523e-05\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 2.7937e-05\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 295us/sample - loss: 2.7363e-05\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 2.6801e-05\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 202us/sample - loss: 2.6250e-05\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 2.5711e-05\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 2.5183e-05\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 2.4665e-05\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 200us/sample - loss: 2.4158e-05\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 198us/sample - loss: 2.3662e-05\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 2.3176e-05\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 2.2700e-05\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 259us/sample - loss: 2.2234e-05\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 183us/sample - loss: 2.1777e-05\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 2.1329e-05\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 2.0891e-05\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 170us/sample - loss: 2.0462e-05\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 208us/sample - loss: 2.0042e-05\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 212us/sample - loss: 1.9630e-05\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 1.9227e-05\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 1.8832e-05\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 569us/sample - loss: 1.8444e-05\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 282us/sample - loss: 1.8066e-05\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 171us/sample - loss: 1.7695e-05\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 262us/sample - loss: 1.7331e-05\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 1.6976e-05\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 1.6627e-05\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 302us/sample - loss: 1.6286e-05\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 288us/sample - loss: 1.5950e-05\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 284us/sample - loss: 1.5623e-05\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 1.5302e-05\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 194us/sample - loss: 1.4988e-05\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 255us/sample - loss: 1.4680e-05\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 1.4378e-05\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 1.4083e-05\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 1.3795e-05\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 350us/sample - loss: 1.3511e-05\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 1.3234e-05\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 197us/sample - loss: 1.2962e-05\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 1.2695e-05\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 200us/sample - loss: 1.2434e-05\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 204us/sample - loss: 1.2179e-05\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 1.1930e-05\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 271us/sample - loss: 1.1684e-05\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 1.1445e-05\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 195us/sample - loss: 1.1210e-05\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 270us/sample - loss: 1.0979e-05\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 211us/sample - loss: 1.0754e-05\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 1.0533e-05\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 182us/sample - loss: 1.0317e-05\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 172us/sample - loss: 1.0104e-05\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 9.8970e-06\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 185us/sample - loss: 9.6931e-06\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 9.4945e-06\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 203us/sample - loss: 9.2993e-06\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 195us/sample - loss: 9.1083e-06\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 156us/sample - loss: 8.9213e-06\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 285us/sample - loss: 8.7383e-06\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 8.5590e-06\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 166us/sample - loss: 8.3831e-06\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 172us/sample - loss: 8.2110e-06\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 169us/sample - loss: 8.0420e-06\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 178us/sample - loss: 7.8775e-06\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 7.7154e-06\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 7.5569e-06\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 189us/sample - loss: 7.4019e-06\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 212us/sample - loss: 7.2499e-06\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 7.1008e-06\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 6.9554e-06\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 6.8122e-06\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 189us/sample - loss: 6.6726e-06\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 6.5350e-06\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 284us/sample - loss: 6.4012e-06\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 207us/sample - loss: 6.2698e-06\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 6.1409e-06\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 6.0147e-06\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 167us/sample - loss: 5.8914e-06\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 156us/sample - loss: 5.7701e-06\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 5.6520e-06\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 194us/sample - loss: 5.5356e-06\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 267us/sample - loss: 5.4219e-06\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 343us/sample - loss: 5.3107e-06\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 158us/sample - loss: 5.2011e-06\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 285us/sample - loss: 5.0947e-06\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 171us/sample - loss: 4.9898e-06\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 4.8874e-06\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 289us/sample - loss: 4.7869e-06\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 172us/sample - loss: 4.6888e-06\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 202us/sample - loss: 4.5926e-06\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 192us/sample - loss: 4.4978e-06\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 4.4058e-06\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 287us/sample - loss: 4.3151e-06\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 283us/sample - loss: 4.2263e-06\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 194us/sample - loss: 4.1396e-06\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 199us/sample - loss: 4.0543e-06\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 3.9713e-06\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 195us/sample - loss: 3.8900e-06\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 183us/sample - loss: 3.8099e-06\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 170us/sample - loss: 3.7317e-06\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 188us/sample - loss: 3.6548e-06\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 196us/sample - loss: 3.5797e-06\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 186us/sample - loss: 3.5064e-06\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 255us/sample - loss: 3.4341e-06\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 191us/sample - loss: 3.3638e-06\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 187us/sample - loss: 3.2947e-06\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 3.2270e-06\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 3.1609e-06\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 178us/sample - loss: 3.0958e-06\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 190us/sample - loss: 3.0320e-06\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 241us/sample - loss: 2.9697e-06\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 193us/sample - loss: 2.9087e-06\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 297us/sample - loss: 2.8488e-06\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 2.7904e-06\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 279us/sample - loss: 2.7334e-06\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 194us/sample - loss: 2.6769e-06\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 201us/sample - loss: 2.6221e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8cac83be48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik0IV1Wxk21c",
        "colab_type": "code",
        "outputId": "0b18be14-86ba-41f6-ca0d-ac993d102099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict([30])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[91.01842]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpjNrSGblm-p",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Learn Tensorflow 2: Introduction to Computer Vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcjCGkyclx6o",
        "colab_type": "code",
        "outputId": "a9bd4a8b-1cbf-426b-b9a7-e59af457a66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9kkxInOl3Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHDv_UhFmC8O",
        "colab_type": "code",
        "outputId": "69b59f67-fa3e-4b14-d47a-a60f68ccc67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(mnist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.util.deprecation_wrapper.DeprecationWrapper"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m14qNG9l-k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIM6i0lsmhtf",
        "colab_type": "code",
        "outputId": "49828e4e-e670-41ee-b885-bbcd97d14795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHmnMZCLmpzx",
        "colab_type": "code",
        "outputId": "83c8a5d8-65a1-415d-c3d1-1ec8138960d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1238
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFE1JREFUeJzt3WtwlFWaB/D/053OhdABAhgQM4KK\nF0ZXdCJ4K8cRdZCyFh1nLS3LxSprsHZ1amfWD1rObK37ZcuyVi1r3Z3ZqKy4NTqzUyMlY1GOGlcZ\nbwwRGVFYRCEKCEkgkoQknfTl2Q95dQPmPG/T3em38fx/VRSdfvqkT7rzz9vd5z3niKqCiPwTi7oD\nRBQNhp/IUww/kacYfiJPMfxEnmL4iTzF8BN5iuEn8hTDT+SpqnLeWbXUaC3qy3mXRF5JYQAjOiz5\n3Lao8IvIUgCPAogDeEJVH7BuX4t6LJYlxdwlERk2aFvety34Zb+IxAH8G4BrACwAcLOILCj0+xFR\neRXznn8RgI9VdaeqjgD4NYDlpekWEU20YsI/B8DuMV/vCa47goisFJF2EWlPY7iIuyOiUprwT/tV\ntVVVW1S1JYGaib47IspTMeHfC6B5zNcnBdcR0XGgmPBvBDBfROaJSDWAmwCsLU23iGiiFTzUp6oZ\nEbkLwB8wOtS3SlU/LFnPiGhCFTXOr6rrAKwrUV+IqIx4ei+Rpxh+Ik8x/ESeYviJPMXwE3mK4Sfy\nFMNP5CmGn8hTDD+Rpxh+Ik8x/ESeYviJPMXwE3mqrEt3UwQkZBVn1aK+fXx6o1n/4vunO2sNz7xT\n1H2H/WxSlXDWND1S3H0XK+x5sRT5nH2JR34iTzH8RJ5i+Ik8xfATeYrhJ/IUw0/kKYafyFMc5/+G\nk3jcrGsmY9ZjC+29V7fdMdluP+SuJQYWmW2rhnJmPfFSu1kvaiw/7ByCkMcVYh9Xi+mbVBmxtZ/O\nI/DIT+Qphp/IUww/kacYfiJPMfxEnmL4iTzF8BN5qqhxfhHpANAPIAsgo6otpegUlY45Jozwcf7d\n359q1m+56I9m/c3uU5y1T2tmmW21ziyj6sqLzPrp/77XWct0fGZ/85A582GPW5j4tGnuYjZrts32\n9bmLxzDVvxQn+XxPVQ+U4PsQURnxZT+Rp4oNvwJ4SUTeFZGVpegQEZVHsS/7L1XVvSJyAoCXReR/\nVXX92BsEfxRWAkAtJhV5d0RUKkUd+VV1b/B/F4A1AL42U0NVW1W1RVVbEqgp5u6IqIQKDr+I1ItI\n8svLAK4G8EGpOkZEE6uYl/1NANbI6NTHKgDPqOqLJekVEU24gsOvqjsBnFvCvtAEyKVSRbUfOe+w\nWf/hFHtOfW0s7ay9HrPn6+99tdmsZ//C7tunDyedtdx7F5ttp39gj7U3vLfPrB+4bI5Z7/6Oe0C+\nKWQ7g2mvfOKsSU/+keZQH5GnGH4iTzH8RJ5i+Ik8xfATeYrhJ/KUaIm2+81HgzTqYllStvvzhrXM\ndMjze/jGC836NT9/zayfVfu5We/P1TprI1rc2eWPbf+uWR/YOcVZi42EbJEdUs422Utva9o+rk7b\n5P7Z65Z3mm3l8ZnO2vttj+Jwz+689v/mkZ/IUww/kacYfiJPMfxEnmL4iTzF8BN5iuEn8hTH+StB\nyHbQRQl5fs9+1/77/4Np9pTdMHFjLekBrTbbHsrWF3Xf3Rn3lN50yDkGT+ywp/weNs4hAIBYxn5O\nr/ree87aDY0bzbYPnnqOs7ZB29CnPRznJyI3hp/IUww/kacYfiJPMfxEnmL4iTzF8BN5qhS79FKx\nyniuxdF2HD7BrB9smGzW92fsLbynx93LaydjQ2bbuQl78+furHscHwDiCffS4CMaN9v+07d/b9ZT\nZyXMekLspb8vNtZB+Kutf222rcdOs54vHvmJPMXwE3mK4SfyFMNP5CmGn8hTDD+Rpxh+Ik+FjvOL\nyCoA1wLoUtWzg+saAfwGwFwAHQBuVNUvJq6bNFFm1tjbXNeKe4ttAKiWjFn/PD3NWdsxdIbZ9qM+\n+xyEpU0fmvW0MZZvrTMAhI/Tn5iwf91Tap8HYD2qlzTZ4/ibzWr+8jnyPwVg6VHX3QugTVXnA2gL\nviai40ho+FV1PYCeo65eDmB1cHk1gOtK3C8immCFvudvUtV9weX9AJpK1B8iKpOiP/DT0UUAnW+g\nRGSliLSLSHsaw8XeHRGVSKHh7xSR2QAQ/N/luqGqtqpqi6q2JFBT4N0RUakVGv61AFYEl1cAeL40\n3SGicgkNv4g8C+BtAGeIyB4RuR3AAwCuEpEdAK4Mviai40joOL+q3uwocQH+UglZt1/i9txzzbjH\n2uPT3OPsAPDdqVvMene2wawfyk4y61Pjg85af6bWbNszZH/vM2v2mfVNg3OdtZnV9ji91W8A6BiZ\nYdbn1+w36w92uuPTXHv04NqRMksuc9Z0w9tm27F4hh+Rpxh+Ik8x/ESeYviJPMXwE3mK4SfyFJfu\nrgQhS3dLlf00WUN9u28/y2x7xSR7ieq3UnPM+syqfrNuTaudXdNrtk02pcx62DBjY5V7unJ/ts5s\nOylmn4oe9nOfX20vO/7TV8531pJnHzTbNiSMY/Yx7PbOIz+Rpxh+Ik8x/ESeYviJPMXwE3mK4Sfy\nFMNP5CmO81cASVSb9VzKHu+2zNgyYtYPZO0lpqfG7Kmt1SFLXFtbYV/cuMts2x0yFr9paJ5ZT8bd\nW4DPjNnj9M0Je6x9S6rZrK8bOM2s337tK87as61XmW2rX3zLWRO1n6+xeOQn8hTDT+Qphp/IUww/\nkacYfiJPMfxEnmL4iTx1fI3zG0tcS5U9Xi3xkL9zMbueSxnzu3P2WHcYTdtj8cV49D8eM+u7M1PN\n+v60XQ9b4jprTDB/Z2iK2bY2Zm8PPrOqz6z35ezzBCz9OXtZcWudAiC87/dM3+GsPdd7pdm2VHjk\nJ/IUw0/kKYafyFMMP5GnGH4iTzH8RJ5i+Ik8FTrOLyKrAFwLoEtVzw6uux/AjwB0Bze7T1XXFduZ\nYtanDxsrV3vYNVJDyxeZ9d3X2ecR3HLen5y1/Zmk2fY9YxtrAJhizIkHgPqQ9e1T6j7/4vMRe/vw\nsLFya11+ADjBOA8gq/Zxb2/a7luYsPMf9mSMPQX+0l5rYOrTBXXpa/I58j8FYOk41z+iqguDf0UH\nn4jKKzT8qroeQE8Z+kJEZVTMe/67ROR9EVklIsW9RiKisis0/L8AcCqAhQD2AXjIdUMRWSki7SLS\nnob9/pCIyqeg8Ktqp6pmVTUH4HEAzk+sVLVVVVtUtSWBmkL7SUQlVlD4RWT2mC+vB/BBabpDROWS\nz1DfswAuBzBDRPYA+EcAl4vIQgAKoAPAHRPYRyKaAKIhe8OXUoM06mJZUrb7G6tq9iyznp7XZNZ7\nznLvBT84y94UfeGybWb9tqY3zHp3tsGsJ8R9/kPYPvSzEofM+qu9C8z65Cr7cxzrPIHz6zrMtody\n7sccAE6s+sKs3/PxD521pkn2WPoTJ9uj12nNmfXtafstbjLmPi/lj4P2mv9rFsx01jZoG/q0x/6F\nDPAMPyJPMfxEnmL4iTzF8BN5iuEn8hTDT+Spilq6e/iaC8z6CT/b6awtbNhjtl1QZw+npXL20t/W\n9NKtQ3PMtoM5ewvuHSP2MGRvxh7yiot72KlrxJ7S+9Aue5notkW/NOs//3y8CZ//L1bnHko+mJ1s\ntr1hsr00N2A/Z3d8a72zdkp1l9n2hYHZZv3zkCm/TYlesz430e2s/SD5kdl2DdxDfceCR34iTzH8\nRJ5i+Ik8xfATeYrhJ/IUw0/kKYafyFPlHecXe3nuxf+80Wy+JPmhszao9hTKsHH8sHFby5Qqe5nm\n4bT9MHel7Sm7YU6v2e+sXd+w2Wy7/rHFZv3S1I/N+idX/KdZbxtyb2XdnbF/7pt2XWHWN33WbNYv\nnLvLWTsnuddsG3ZuRTKeMuvWNGsAGMi5f1/fSdnnP5QKj/xEnmL4iTzF8BN5iuEn8hTDT+Qphp/I\nUww/kafKunR33axmPfXWv3fWW+/8V7P9Mz0XOmvNtfZeoidXHzDr0+P2ds+WZMwe8z0jYY/5vjBw\nkll/7dCZZv07yQ5nLSH29t6XT/rYrN/207vNeqbWXiW6b677+JKpt3/3Gs49aNZ/fNqrZr3a+NkP\nZe1x/LDHLWwL7jDWGgzJmL0t+kPLrnfW3u54Cr1D+7h0NxG5MfxEnmL4iTzF8BN5iuEn8hTDT+Qp\nhp/IU6Hz+UWkGcDTAJoAKIBWVX1URBoB/AbAXAAdAG5UVXPP5FgamNTpHt98oW+h2ZdT6txrnR9I\n2+vT/+HwOWb9pDp7u2drq+nTjPn0ALA5NdWsv9j9bbN+Yp29fn1neoqzdjBdb7YdNOaVA8CTjzxs\n1h/qtNf9v75xk7N2brU9jn8oZx+btobsd9Cfq3XWUmqv79Abch5A0vh9AIC02tGKG1t8T43Z5xD0\nnTPdWct25r9ERz5H/gyAu1V1AYALAdwpIgsA3AugTVXnA2gLviai40Ro+FV1n6puCi73A9gGYA6A\n5QBWBzdbDeC6ieokEZXeMb3nF5G5AM4DsAFAk6ruC0r7Mfq2gIiOE3mHX0QmA/gdgJ+o6hFvQnV0\ngsC4J2qLyEoRaReR9szwQFGdJaLSySv8IpLAaPB/parPBVd3isjsoD4bwLg7H6pqq6q2qGpLVY39\n4RMRlU9o+EVEADwJYJuqjv3ody2AFcHlFQCeL333iGii5DMucAmAWwFsEZEv14G+D8ADAP5bRG4H\n8CmAG8O+UXwkh+TuYWc9p/ZMxFcPuKe2NtX2m20XJneb9e2D9rDRlqETnbVNVd8y29bF3dt7A8CU\nantKcH2V+zEDgBkJ988+r8beitqa9goAG1P2z/Y3M18z659l3Eui/37gdLPt1kH3Yw4A00KWTN/S\n524/mLG3TR/O2tFIZeyh4yk19nN6QeOnztp22NuDd59rTJN+02x6hNDwq+obAFypXJL/XRFRJeEZ\nfkSeYviJPMXwE3mK4SfyFMNP5CmGn8hT5d2i+/AQYq+/5yz/9qVLzOb/sPy3ztrrIctbv7DfHpft\nG7Gnts6c5D41ucEYZweAxoR9WnPYFt+1Ids9f5Fxnzk5HLOnrmado7ij9g+7pwsDwJu5+WY9nXNv\n0T1s1IDw8yN6RmaY9RPrep21/ox7ui8AdPQ3mvUDvfY22qlJdrTeyJ7qrC2d5d6KHgDqutzPWcz+\nVTnytvnflIi+SRh+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5KmybtHdII26WAqfBdx7i3uL7lP+drvZ\ndtHUXWZ9U589b/0zY9w3HbLEdCLmXqYZACYlRsx6bch4d3XcPSc/Nv7qal/JhYzz18ftvoWtNdBQ\n5Z7Xnozbc95jxjbW+YgbP/ufeucW9b2TIT93Ru3fiYumfOKsrdp1sdl2yjL3tuobtA192sMtuonI\njeEn8hTDT+Qphp/IUww/kacYfiJPMfxEnir/OH/8avcNcvYa8sUYuGGxWV9830a7nnSPy55Z3Wm2\nTcAer64NGc+uj9nDtinjOQz76/7GULNZz4Z8h1e/OMusp43x7s7BBrNtwjh/IR/WPhBDmZAtuofs\n+f7xmJ2b1Gv2WgPTt7rP3ahZZ/8uWjjOT0ShGH4iTzH8RJ5i+Ik8xfATeYrhJ/IUw0/kqdBxfhFp\nBvA0gCYACqBVVR8VkfsB/AhAd3DT+1R1nfW9ip3PX6nkAntPgKFZdWa95qA9N7z/ZLt9wyfufQFi\nw/ZC7rk/bzPrdHw5lnH+fDbtyAC4W1U3iUgSwLsi8nJQe0RV/6XQjhJRdELDr6r7AOwLLveLyDYA\ncya6Y0Q0sY7pPb+IzAVwHoANwVV3icj7IrJKRKY52qwUkXYRaU/DfnlLROWTd/hFZDKA3wH4iar2\nAfgFgFMBLMToK4OHxmunqq2q2qKqLQnY++ERUfnkFX4RSWA0+L9S1ecAQFU7VTWrqjkAjwNYNHHd\nJKJSCw2/iAiAJwFsU9WHx1w/e8zNrgfwQem7R0QTJZ9P+y8BcCuALSKyObjuPgA3i8hCjA7/dQC4\nY0J6eBzQjVvMuj05NFzDW4W3LW7xa/omy+fT/jeAcRd3N8f0iaiy8Qw/Ik8x/ESeYviJPMXwE3mK\n4SfyFMNP5CmGn8hTDD+Rpxh+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5KmybtEtIt0APh1z1QwAB8rW\ngWNTqX2r1H4B7FuhStm3k1V1Zj43LGv4v3bnIu2q2hJZBwyV2rdK7RfAvhUqqr7xZT+Rpxh+Ik9F\nHf7WiO/fUql9q9R+AexboSLpW6Tv+YkoOlEf+YkoIpGEX0SWish2EflYRO6Nog8uItIhIltEZLOI\ntEfcl1Ui0iUiH4y5rlFEXhaRHcH/426TFlHf7heRvcFjt1lElkXUt2YR+R8R2SoiH4rI3wXXR/rY\nGf2K5HEr+8t+EYkD+AjAVQD2ANgI4GZV3VrWjjiISAeAFlWNfExYRC4DcBjA06p6dnDdgwB6VPWB\n4A/nNFW9p0L6dj+Aw1Hv3BxsKDN77M7SAK4DcBsifOyMft2ICB63KI78iwB8rKo7VXUEwK8BLI+g\nHxVPVdcD6Dnq6uUAVgeXV2P0l6fsHH2rCKq6T1U3BZf7AXy5s3Skj53Rr0hEEf45AHaP+XoPKmvL\nbwXwkoi8KyIro+7MOJqCbdMBYD+Apig7M47QnZvL6aidpSvmsStkx+tS4wd+X3epqp4P4BoAdwYv\nbyuSjr5nq6Thmrx2bi6XcXaW/kqUj12hO16XWhTh3wugeczXJwXXVQRV3Rv83wVgDSpv9+HOLzdJ\nDf7virg/X6mknZvH21kaFfDYVdKO11GEfyOA+SIyT0SqAdwEYG0E/fgaEakPPoiBiNQDuBqVt/vw\nWgArgssrADwfYV+OUCk7N7t2lkbEj13F7XitqmX/B2AZRj/x/wTAz6Log6NfpwD4c/Dvw6j7BuBZ\njL4MTGP0s5HbAUwH0AZgB4BXADRWUN/+C8AWAO9jNGizI+rbpRh9Sf8+gM3Bv2VRP3ZGvyJ53HiG\nH5Gn+IEfkacYfiJPMfxEnmL4iTzF8BN5iuEn8hTDT+Qphp/IU/8Hi09KHGksOg4AAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhMd4Yz9mkka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_images = training_images / 255.0\n",
        "# test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtdGOxLjlwQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mssOwakcoDaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSq-2yo0lt9Y",
        "colab_type": "code",
        "outputId": "05374b33-5a96-4d69-8f1a-276a07e5457d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-05546c560f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2558\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m       \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2774\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       raise TypeError('Unable to build `Dense` layer with non-floating point '\n\u001b[0;32m-> 1002\u001b[0;31m                       'dtype %s' % (dtype,))\n\u001b[0m\u001b[1;32m   1003\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unable to build `Dense` layer with non-floating point dtype <dtype: 'uint8'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcRwZoLKoZFA",
        "colab_type": "code",
        "outputId": "8f3fb444-2535-4059-8745-4f00256dfceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 58us/sample - loss: 0.3407 - acc: 0.8774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3406799352169037, 0.8774]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSWFNbWyol55",
        "colab_type": "code",
        "outputId": "dee56624-d377-4cd5-d864-89a76218c96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "classifications = model.predict(test_images[:10])\n",
        "print(classifications[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.2840222e-07 5.3604126e-09 1.4408175e-07 1.2810296e-08 5.0912242e-08\n",
            " 1.2603528e-03 3.8166016e-07 5.4722305e-02 6.2595927e-07 9.4401562e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89IOZn7UosZi",
        "colab_type": "code",
        "outputId": "12e6e351-a741-44f2-faa5-682a4c160135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "#training_images=training_images/255.0\n",
        "#test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0-rc1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-4601bff01fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mclassifications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2558\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m       \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2774\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       raise TypeError('Unable to build `Dense` layer with non-floating point '\n\u001b[0;32m-> 1002\u001b[0;31m                       'dtype %s' % (dtype,))\n\u001b[0m\u001b[1;32m   1003\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unable to build `Dense` layer with non-floating point dtype <dtype: 'uint8'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqsm7aG1kp85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILoL_HBJqQjP",
        "colab_type": "code",
        "outputId": "8737582d-8b9d-4d50-b294-99ed129e97d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.65):\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8313\n",
            "Reached 95% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.4732 - acc: 0.8314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8ca3e83b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waHfM0u1ktES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_DHY8nEkruC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#Add another convolution\n",
        "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D(2,2),\n",
        "#Now flatten the output. After this you'll just have the same DNN structure as the non convolutional version\n",
        "tf.keras.layers.Flatten(),\n",
        "#The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
        "tf.keras.layers.Dense(128, activation='relu'),\n",
        "tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPyqyn7JrI62",
        "colab_type": "code",
        "outputId": "1b78127c-b671-46f0-9874-90564cf906d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ab80Q5lBTN",
        "colab_type": "code",
        "outputId": "5b9d77e4-f666-4abd-9b8a-c2891e15dd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 225,034\n",
            "Trainable params: 225,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmEepJErlWA0",
        "colab_type": "code",
        "outputId": "43561d31-d8dd-41e2-b67f-75e5b234623f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print (\"Test loss: {}, Test accuracy: {}\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 58s 961us/sample - loss: 0.2500 - acc: 0.9081\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 59s 977us/sample - loss: 0.2149 - acc: 0.9203\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 57s 955us/sample - loss: 0.1913 - acc: 0.9289\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 57s 956us/sample - loss: 0.1676 - acc: 0.9373\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 58s 964us/sample - loss: 0.1482 - acc: 0.9437\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.2965 - acc: 0.9032\n",
            "Test loss: 0.2965314450860024, Test accuracy: 90.31999707221985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt_WCF5Tmc3H",
        "colab_type": "code",
        "outputId": "1552b3dc-ffd6-48d6-91f2-3765b03f0af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "576 * 32 + 64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNKprjw7qlBN",
        "colab_type": "code",
        "outputId": "0db8be3a-0723-42ab-e95d-c9c6c9a8774d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(3 * 3 * 32) + 32"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIb2L9oH4nPX",
        "colab_type": "code",
        "outputId": "f5f9a376-589a-412c-8086-0c671ab4cd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/pjreddie/darknet.git\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 5901, done.\u001b[K\n",
            "remote: Total 5901 (delta 0), reused 0 (delta 0), pack-reused 5901\u001b[K\n",
            "Receiving objects: 100% (5901/5901), 6.16 MiB | 27.32 MiB/s, done.\n",
            "Resolving deltas: 100% (3927/3927), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-IPDDXu46qI",
        "colab_type": "code",
        "outputId": "82d52650-d678-4125-c404-3ede35f6373a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1210
        }
      },
      "source": [
        "! cd darknet; make"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir -p obj\n",
            "mkdir -p backup\n",
            "mkdir -p results\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/gemm.c -o obj/gemm.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/utils.c -o obj/utils.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/cuda.c -o obj/cuda.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/deconvolutional_layer.c -o obj/deconvolutional_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/list.c -o obj/list.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/image.c -o obj/image.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/activations.c -o obj/activations.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/im2col.c -o obj/im2col.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/col2im.c -o obj/col2im.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/blas.c -o obj/blas.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/crop_layer.c -o obj/crop_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/dropout_layer.c -o obj/dropout_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/maxpool_layer.c -o obj/maxpool_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/softmax_layer.c -o obj/softmax_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/data.c -o obj/data.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/matrix.c -o obj/matrix.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/network.c -o obj/network.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/connected_layer.c -o obj/connected_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/cost_layer.c -o obj/cost_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/parser.c -o obj/parser.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/option_list.c -o obj/option_list.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/detection_layer.c -o obj/detection_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/route_layer.c -o obj/route_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/upsample_layer.c -o obj/upsample_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/box.c -o obj/box.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/normalization_layer.c -o obj/normalization_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/avgpool_layer.c -o obj/avgpool_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/layer.c -o obj/layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/local_layer.c -o obj/local_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/shortcut_layer.c -o obj/shortcut_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/logistic_layer.c -o obj/logistic_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/activation_layer.c -o obj/activation_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/rnn_layer.c -o obj/rnn_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/gru_layer.c -o obj/gru_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/crnn_layer.c -o obj/crnn_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/demo.c -o obj/demo.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/batchnorm_layer.c -o obj/batchnorm_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/region_layer.c -o obj/region_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/reorg_layer.c -o obj/reorg_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/tree.c -o obj/tree.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/lstm_layer.c -o obj/lstm_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/l2norm_layer.c -o obj/l2norm_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/yolo_layer.c -o obj/yolo_layer.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/iseg_layer.c -o obj/iseg_layer.o\n",
            "g++ -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "gcc -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -shared obj/gemm.o obj/utils.o obj/cuda.o obj/deconvolutional_layer.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/detection_layer.o obj/route_layer.o obj/upsample_layer.o obj/box.o obj/normalization_layer.o obj/avgpool_layer.o obj/layer.o obj/local_layer.o obj/shortcut_layer.o obj/logistic_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/crnn_layer.o obj/demo.o obj/batchnorm_layer.o obj/region_layer.o obj/reorg_layer.o obj/tree.o obj/lstm_layer.o obj/l2norm_layer.o obj/yolo_layer.o obj/iseg_layer.o obj/image_opencv.o -o libdarknet.so -lm -pthread \n",
            "ar rcs libdarknet.a obj/gemm.o obj/utils.o obj/cuda.o obj/deconvolutional_layer.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/detection_layer.o obj/route_layer.o obj/upsample_layer.o obj/box.o obj/normalization_layer.o obj/avgpool_layer.o obj/layer.o obj/local_layer.o obj/shortcut_layer.o obj/logistic_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/crnn_layer.o obj/demo.o obj/batchnorm_layer.o obj/region_layer.o obj/reorg_layer.o obj/tree.o obj/lstm_layer.o obj/l2norm_layer.o obj/yolo_layer.o obj/iseg_layer.o obj/image_opencv.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/captcha.c -o obj/captcha.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/lsd.c -o obj/lsd.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/super.c -o obj/super.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/art.c -o obj/art.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/tag.c -o obj/tag.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/cifar.c -o obj/cifar.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/go.c -o obj/go.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/rnn.c -o obj/rnn.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/segmenter.c -o obj/segmenter.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/regressor.c -o obj/regressor.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/classifier.c -o obj/classifier.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/coco.c -o obj/coco.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/yolo.c -o obj/yolo.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/detector.c -o obj/detector.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/nightmare.c -o obj/nightmare.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/instance-segmenter.c -o obj/instance-segmenter.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/darknet.c -o obj/darknet.o\n",
            "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast obj/captcha.o obj/lsd.o obj/super.o obj/art.o obj/tag.o obj/cifar.o obj/go.o obj/rnn.o obj/segmenter.o obj/regressor.o obj/classifier.o obj/coco.o obj/yolo.o obj/detector.o obj/nightmare.o obj/instance-segmenter.o obj/darknet.o libdarknet.a -o darknet -lm -pthread  libdarknet.a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnYgKUq34_HH",
        "colab_type": "code",
        "outputId": "6f5b0961-8708-43a9-ae96-2a930de4a3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!./darknet/darknet  -i 1 imagenet test cfg/alexnet.cfg alexnet.weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not an option: imagenet\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}